{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 원 위치 : https://www.tensorflow.org/get_started/tflearn\n",
    "\n",
    "라인 6, 22, 27의 urllib를 urllib.request로 수정.\n",
    "라인 13, 16의 csv파일 위치를 ../ 로 변경. Azure notebook에서 업로드 하면 ../로 올라간다.\n",
    "\n",
    "다음 2개의 파일을 다운로드하고 메뉴 Data > Upload... 를 사용하여 업로드한다.\n",
    "- http://download.tensorflow.org/data/iris_training.csv\n",
    "- http://download.tensorflow.org/data/iris_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022D6DD581C8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'iris_model', '_session_creation_timeout_secs': 7200}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from iris_model\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into iris_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.032711457, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 1667.48\n",
      "INFO:tensorflow:loss = 0.03241765, step = 4101 (0.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 2325.58\n",
      "INFO:tensorflow:loss = 0.032125246, step = 4201 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2272.67\n",
      "INFO:tensorflow:loss = 0.03184626, step = 4301 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2325.65\n",
      "INFO:tensorflow:loss = 0.031575266, step = 4401 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2272.65\n",
      "INFO:tensorflow:loss = 0.031304583, step = 4501 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2325.66\n",
      "INFO:tensorflow:loss = 0.031039473, step = 4601 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2272.62\n",
      "INFO:tensorflow:loss = 0.030791575, step = 4701 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2272.84\n",
      "INFO:tensorflow:loss = 0.030534098, step = 4801 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2325.58\n",
      "INFO:tensorflow:loss = 0.030302472, step = 4901 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2272.72\n",
      "INFO:tensorflow:loss = 0.030064236, step = 5001 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2261.43\n",
      "INFO:tensorflow:loss = 0.029829709, step = 5101 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2379.34\n",
      "INFO:tensorflow:loss = 0.029606126, step = 5201 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2274.11\n",
      "INFO:tensorflow:loss = 0.029394846, step = 5301 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2325.69\n",
      "INFO:tensorflow:loss = 0.02917422, step = 5401 (0.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 2325.61\n",
      "INFO:tensorflow:loss = 0.028980196, step = 5501 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2324.46\n",
      "INFO:tensorflow:loss = 0.028777173, step = 5601 (0.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 2326.7\n",
      "INFO:tensorflow:loss = 0.028573418, step = 5701 (0.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 2222.22\n",
      "INFO:tensorflow:loss = 0.028390057, step = 5801 (0.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 2222.29\n",
      "INFO:tensorflow:loss = 0.028202113, step = 5901 (0.045 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.027844569.\n",
      "INFO:tensorflow:Starting evaluation at 2022-03-15T14:23:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from iris_model\\model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2022-03-15-14:23:48\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.96666664, global_step = 6000, loss = 0.10994892\n",
      "\n",
      "Test Accuracy: 0.966667\n",
      "\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from iris_model\\model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "New Samples, Class Predictions:    [1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow as TF\n",
    "\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"./iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"./iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def main():\n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urllib.request.urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urllib.request.urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  # Load datasets.\n",
    "  training_set = TF.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=int,\n",
    "      features_dtype=np.float32)\n",
    "  test_set = TF.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=int,\n",
    "      features_dtype=np.float32)\n",
    "\n",
    "  # Specify that all features have real-value data\n",
    "  feature_columns = [TF.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "  classifier = TF.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[10, 20, 10],\n",
    "                                              n_classes=3,\n",
    "                                              model_dir=\"iris_model\")\n",
    "  # Define the training inputs\n",
    "  def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "  # Fit model.\n",
    "  classifier.fit(input_fn=get_train_inputs, steps=2000)\n",
    "\n",
    "  # Define the test inputs\n",
    "  def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "  # Evaluate accuracy.\n",
    "  accuracy_score = classifier.evaluate(input_fn=get_test_inputs,\n",
    "                                       steps=1)[\"accuracy\"]\n",
    "\n",
    "  print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "  # Classify two new flower samples.\n",
    "  def new_samples():\n",
    "    return np.array(\n",
    "      [[6.4, 3.2, 4.5, 1.5],\n",
    "       [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
    "\n",
    "  predictions = list(classifier.predict(input_fn=new_samples))\n",
    "\n",
    "  print(\n",
    "      \"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predictions))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
